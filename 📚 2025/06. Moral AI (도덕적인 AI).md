---
title: Moral AI (도덕적인 AI)
subtitle:
author: Walter Sinnott-Armstrong, Jana Schaich Borg, Vincent Conitzer
translator: 박초월
publisher: 김영사
published date: 2025
date read: 10/2025
tags:
  - AI
  - 도덕
  - 윤리
---
## About Authors ##
1. Walter Sinnott- Armstrong
	- 철학자이자 윤리학자이며 듀크대학교 철학과 실천윤리학 교수이다. 
	- 듀크대 로스쿨과 심리학 및 신경과학과의 겸임교수이기도 하며
	- 인지신경 과학센터와 뇌과학 연구소에서도 책임자로 일하고 있다. 
2. Jana Schaich Borg
	- 신경과학자이자 데이터 과학자이며 듀크대에서 사회과학연구소 조교수로 일하고 있다. 
	- 암스트롱과 같이 '도덕적 태도와 걱정 연구소'의 공통소장으로도 일하고 있다. 
3. Vincent Conitzer
	- 컴퓨터 과학자이자 게임 이론가이다. 
	- 카네기 멜론대학교에서 컴퓨터과학 교수이며 협력적 AI연구소 (FOCAL)의 소장이기도 하다. 
	- 옥스포드 대 AI윤리연구소의 AI 기술책임자와 CS 및 철학교수이기도 하다. 
## Summary

이 책의 저자들은 AI가 제기하는 세 가지 주요 윤리 문제에 깊은 우려를 표하며, **AI의 도덕적 피해를 최소화하면서 혁신을 지속할 수 있는 실행 가능한 방안을 제시하는 것**을 목표로 한다.  
그들은 AI를 비관적으로만 보거나 낙관적으로만 볼 필요가 없다고 말한다. 종종 동일한 기술과 적용 사례 안에서도 **두려움과 희망이 공존**하기 때문이다.

예를 들어, IBM의 의료용 AI는 한 여성 환자의 급성 백혈병을 조기 진단하여 빠르게 치료할 수 있도록 도왔다. 그러나 반대로, 현재 의료 현장에서 사용하는 ‘고위험군 돌봄’ 예측 AI는 편향된 데이터를 기반으로 훈련되어 **흑인 환자보다 백인 환자를 우선시하는 결과**를 낳기도 한다. 두 환자가 동일한 질병 수준임에도 불구하고 말이다.

이처럼 AI가 사회에 가져올 잠재적 편익과 위험을 평가하기 위해서는 **AI의 본질과 한계를 명확히 이해하는 것이 필수적**이다.  
AI의 위험성을 과소평가해서는 안 되지만, 동시에 과대평가하는 것도 경계해야 한다.

저자들은 다음과 같은 근본적인 질문을 던진다.  
“인공지능이란 무엇인가? 인공지능은 안전할 수 있는가? 프라이버시를 존중하고, 공정하며, 책임을 질 수 있는가? 그리고 인간의 도덕성을 탑재할 수 있는가?”

결국 인공지능이 ‘지능’을 지녔다고 해서 **실수를 하지 않는다는 의미는 아니다**. 인간 또한 지능이 있음에도 불구하고 실수를 저지르듯, 인간이 만든 존재인 AI 역시 오류를 범할 수 있다. 따라서 AI에 대한 **무비판적 신뢰는 심각한 피해로 이어질 수 있으며**, 진정한 의미의 ‘도덕적 AI’를 만들기 위해서는 **AI를 만드는 사람, 관리하는 사람, 사용하는 사람 모두가 도덕적 지능을 갖춰야 한다**.

저자들은 마지막에 이렇게 강조한다.  
“AI에 대해 생각할 때 우리는 우리의 역할을 명확히 해야 한다. AI는 단지 우리와 함께 가는 존재일 뿐이다.”  
결국 **도덕적인 AI를 만들기 위해서는 도덕적인 사회, 도덕적인 공동체, 그리고 도덕적인 인간이 먼저 필요하다**는 메시지를 전달하는 책이었다.

---

## Reflection

AI를 공부하고, 나아가 AI 관련 일을 업으로 삼고 싶은 사람으로서 이 책은 새로운 시각으로 AI를 보게되었다. 
인공지능이 세상에 등장한 지 약 70년이 되었고, 기술 발전으로 인해 지금 우리는 ‘AI 붐’이라 부를 만큼 급속한 변화를 경험하고 있다. 그러나 그 성장 속도에 비해 **AI의 도덕성과 윤리성은 따라오지 못하고 있으며**, 그로 인한 사회적 피해 역시 점점 커지고 있다.

그런데 책을 읽으며, 나는 오히려 **AI의 부족한 점에서 나 자신을 보았다.**  
저자들은 AI와 인간 지능의 차이를 여러 측면에서 설명했다.  
AI는 기본 상식이 부족해 문맥 이해가 제한적이고, 세상이 어떻게 작동하는지 넓게 파악하지 못해 유연성이 부족하다. 또한 틀을 벗어난 사고를 하지 못하고, 감정적·사회적 통찰이 결여되어 있다.  
그런데 이 결함들은 단지 인공지능의 문제가 아니라 **성숙하지 못한 인간의 문제와도 동일**했다.

즉, 인공지능의 도덕적 문제뿐 아니라 **AI가 지닌 구조적 한계 대부분이 결국 인간에게서 비롯된 문제**라는 사실을 깨달았다. 그럼에도 불구하고 우리는 마치 인간은 완벽하고 AI만 미숙하다는 듯 비판한다. 이는 큰 착각이다.

저자들은 실질적 해결책으로 ‘윤리 지표(Ethical Metrics)’의 구축을 제안한다.  
기술 발전만 추구할 것이 아니라 **객관적인 윤리 평가 체계를 마련하고, 그에 따라 규제를 지속적으로 조정해야 한다**는 것이다.  
이 대목을 읽으며, 나는 나 자신에게도 같은 원리를 적용할 수 있음을 깨달았다.  
나는 한때 지식과 기술, 외적 성취에만 집중하며 그것이 성장이라고 믿었다. 하지만 그 시절의 나는 가장 공허했다.  
내면의 윤리적 기준, 성숙한 인간으로서의 지표를 세우지 못했기 때문이다.

AI가 인간의 도덕성을 반영해야 하듯, **나 역시 나의 내면적 기준을 정립하지 못하면 어떤 지식이나 성취도 의미가 없다는 것을** 절감했다.  
결국 도덕적 성찰과 자기 인식이 없는 성장은 방향을 잃은 확장일 뿐이다.

AI를 만들고 사용하는 주체는 결국 인간이다.  
따라서 인간이 건강한 사고를 하지 못한다면, **건강하게 사고하는 AI 역시 결코 만들어질 수 없다.**  
오늘날 많은 이들이 “AI가 인류의 미래를 장악할 것이다”라는 두려움에 사로잡혀 있다.  
하지만 어쩌면 우리의 두려움의 근원은 기술이 아니라 인간 자신에게 있다. 빨리 성장하는 기술 그 자체가 아니라, **스스로가 성숙하게 사고하지 못한다는 사실**인지도 모른다.  
AI의 미래를 걱정하기에 앞서, **우리 자신의 어리석음과 도덕적 미성숙을 먼저 성찰해야 한다**는 점을 알아차리게 해준 책이었다.

### Notes ###
